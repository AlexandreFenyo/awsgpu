
Je veux développer un pipeline de RAG, pour faire de la genAI.

J'ai déjà produit des chunks à partir d'un document et je veux calculer leurs embeddings. Ils seront envoyés, via un autre script, dans une base Weaviate.

Les metadata de contexte des chunks comprennent :
  - les mots clés importants du chunk.
  - les différents niveaux de titres.
Voici un exemple de chunk :
{"chunk_id": "CCTP.docx-571", "text": "* Définit les besoins fonctionnels des SI de l’Assurance Maladie dans son champ d'activité et s'assure de leur mise en œuvre,", "metadata": {"headings": {"h1": "Présentation de l’Assurance Maladie et du Numérique en Santé", "h2": "La Direction déléguée à la gestion et à l’organisation des soins (DDGOS)"}, "keywords": ["définit", "besoins", "fonctionnels", "assurance", "maladie"]}, "approx_tokens": 21}

Je veux désormais un script qui crée les embeddings, au format NDJSON.

Ce script prend en entrée le nom du fichier des chunks.
Le nom de fichier de sortie contenant les embeddings est composé du nom de fichier d'entrée auquel on ajoute le suffixe ".embeddings.ndjson".
Le script affiche le nom du fichier produit.

Le fichier ndjson à produire est constitué d'une ligne par chunk, au format suivant :
{ chunk_id, embedding: [floats], model: {name, version}, created_at, approx_tokens, keywords, headings }

En voici un exemple :
{"chunk_id": "CCTP.docx-571", "embedding": [0.012, -0.439, ..., 0.204], "model": {"name": "embed-model-x", "version": "1.2.0"}, "created_at": "2025-08-15T12:30:00Z", "approx_tokens": 21, "keywords": ["définit","besoins","fonctionnels","assurance","maladie"], "headings": {"h1": "Présentation...", "h2": "La Direction ..."}}

Le script s'appuie sur sentence-transformer, avec le modèle paraphrase-xlm-r-multilingual-v1.

# poetry add sentence_transformers

------------------------------------------------------------

Modifie le format du fichier ndjson, pour qu'en plus d'avoir le chunk_id, j'ai aussi le texte associé au chunk.



Je veux développer un pipeline de RAG, pour faire de la genAI.

J'ai déjà produit des chunks à partir d'un document et j'ai calculé leurs embeddings.
Je dois maintenant les envoyer, via ce nouveau script, dans une base Weaviate.

Le fichier d'entrée contient les embeddings au format NDJON, constitué d'une ligne par chunk, au format suivant :
{ chunk_id, embedding: [floats], model: {name, version}, created_at, approx_tokens, keywords, headings }

Voici un exemple d'une ligne de ce fichier :
{"chunk_id": "CCTP.docx-2322", "embedding": [0.19614559412002563, -0.016328079625964165, 0.21465414762496948, 0.29702073335647583, ...], "model": {"name": "paraphrase-xlm-r-multilingual-v1", "version": "5.1.0"}, "created_at": "2025-08-15T16:54:50Z", "approx_tokens": 13, "keywords": ["supervision", "technique", "applicative", "partagée", "accessible"], "headings": {"h1": "Prestations adressées par l’accord-cadre", "h2": "P1.2 - Rep : Reprise de l’existant", "h3": "Objet"}}

Les metadata de contexte qui sont dans ce fichier comprennent :
  - les mots clés importants du chunk correspondant, placés dans le tableau keywords.
  - les différents niveaux de titres du chunk correspondant, placés dans le tableau headings.
 
Je veux désormais un script qui envoie ces embeddings dans ma base Weaviate locale.

Ce script prend en entrée le nom du fichier des embeddings.
Il s'appuie sur le package Python suivant : weaviate-client.

Il est composé de deux étapes :
- il crée tout d'abord la base avec un schéma adapté, de telle façon que Weaviate ne se charge pas de ré-embedder les données.
- il injecte alors les embeddings du fichier d'entrée.

# poetry install weaviate
# poetry install weaviate-client


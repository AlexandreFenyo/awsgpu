
Je veux analyser un fichier au format NDJSON qui contient des chunks créés pour un pipeline de RAG avec genAI.
Voici un exemple d'un tel chunk :
{
      "chunk_id": "...",
      "text": "...",
      "headings": {"h1": "un titre", "h2": "un nom de section"},
      "heading": {"h2": "un nom de section"},
      "full_headings": "un titre; un nom de section",
      "keywords": ["...", ...],
      "approx_tokens": 123
}

Le texte en français est lié à la clé "text" du JSON et les mots-clés sont dans le tableau lié à la clé "keywords" du JSON.

Un mot-clé est :
- soit un "noun phrase" (c'est à dire ce qu'on appelle un "NP" en linguistique),
- soit une entité nommée,
- soit un NER (spaCy FR) pour capter les noms de produits, de sociétés, d’outils, etc,
- soit une combinaison 1–3 mots qui porte du sens (par ex. “modèle de langage”, “embeddings”, “détection d’anomalies”),
- soit un nom dans une formulation comme "l’outil SCA nommé « OWASP Dependency Check »", où le nom apparaît entre double-quotes, ou entre délimiteurs Markdown pour les italiques ou le gras.

Un mot clé a subi une normalisation via transformation en minuscules et lemmatisation légère, pour éviter les redondances.

Fais un script python qui prend en entrée ce fichier au format NDJSON et qui identifie tous les mots-clés possibles dans le texte associé à la clé "text" de chaque chunk. Renvoie en sortie tous les mots-clés (une par ligne), que tu auras identifiés grace à la bibliothèque spaCy et avec le modèle le fr_core_news_lg pour la langue française.


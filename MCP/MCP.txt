
pip install --upgrade ollama-mcp-bridge

(awsgpu-py3.13) W11% ollama-mcp-bridge --config MCP/mcp-config.json --ollama-url http://192.168.0.21:11434
npm install -g @modelcontextprotocol/server-filesystem
npm install -g @modelcontextprotocol/server-brave-search
npm install -g @modelcontextprotocol/server-github
npm install -g @modelcontextprotocol/server-memory
npm install -g @patruff/server-flux
npm install -g @patruff/server-gmail-drive

mcp-config.json:
{
    "mcpServers": {
	"weather": {
	    "command": "python",
	    "args": [
		"mock-weather-mcp-server.py"
	    ]
	},
	"filesystem": {
	    "command": "npx",
	    "args": [
		"@modelcontextprotocol/server-filesystem",
		"/tmp"
	    ]
	}
    }
}

sans weather:
mcp-config.json:
{
    "mcpServers": {
	"filesystem": {
	    "command": "npx",
	    "args": [
		"@modelcontextprotocol/server-filesystem",
		"/tmp"
	    ]
	}
    }
}

npx @modelcontextprotocol/server-filesystem /tmp


curl -N -H 'Content-Type: application/json' -X POST 'http://192.168.0.21:11434/api/chat' -d '{"model": "gpt-oss:20b", "messages": [{"role": "user", "content": "Combien font 2 + 2 ?"}], "stream": true, "options": {"num_ctx": 131072}}'

curl -N -H 'Content-Type: application/json' -X POST 'http://127.0.0.1:8000/api/chat' -d '{"model": "gpt-oss:20b", "messages": [{"role": "user", "content": "Combien font 2 + 2 ?"}], "stream": false, "options": {"num_ctx": 131072}}'

(awsgpu-py3.13) W11% curl -N -H 'Content-Type: application/json' -X POST 'http://127.0.0.1:8000/api/chat' -d '{"model": "gpt-oss:20b", "messages": [{"role": "user", "content": "Quels sont les noms des fichiers de /tmp ?"}], "stream": false, "options": {"num_ctx": 131072}}'

OLLAMA_URL=http://192.168.0.21:11434/api/chat python src/front/server.py
OLLAMA_URL=http://127.0.0.1:8000/api/chat python src/front/server.py

------------------------------------------------------------

ollama-mcp-bridge --config MCP/mcp-config.json --ollama-url http://192.168.0.21:11434
OLLAMA_URL=http://127.0.0.1:8000/api/chat python src/front/server.py

Quels sont les noms des fichiers de /tmp/tst







{"model": "gpt-oss:20b", "created_at": "2025-09-20T23:28:46.434057Z", "message": {"role": "assistant", "content": "", "tool_calls": [{"function": {"name": "filesystem.list_directory", "arguments": {"path": "/tmp/tst"}}}]}, "done_reason": "stop", "done": true, "total_duration": 888144700, "load_duration": 83737000, "prompt_eval_count": 1190, "prompt_eval_duration": 467640900, "eval_count": 75, "eval_duration": 336263600}
{"model":"gpt-oss:20b","created_at":"2025-09-20T23:28:47.0712677Z","message":{"role":"assistant","content":"","tool_calls":[{"function":{"name":"list_directory","arguments":{"path":"/tmp/tst"}}}]},"done_reason":"stop","done":true,"total_duration":619517400,"load_duration":83287600,"prompt_eval_count":108,"prompt_eval_duration":29516900,"eval_count":116,"eval_duration":505163800}


"message": {"role": "assistant", "content": "", "tool_calls": [{"function": {"name": "filesystem.list_directory", "arguments": {"path": "/tmp/tst"}}}]}, "done_reason": "stop", "done": true, "total_duration": 976683700, "load_duration": 82631600, "prompt_eval_count": 1190, "prompt_eval_duration": 427364900, "eval_count": 103, "eval_duration": 466183800}
{"model":"gpt-oss:20b","created_at":"2025-09-20T23:32:47.8407555Z","message":{"role":"assistant","content":""},"done_reason":"stop","done":true,"total_duration":1614708500,"load_duration":84801300,"prompt_eval_count":108,"prompt_eval_duration":29364900,"eval_count":337,"eval_duration":1498318600}

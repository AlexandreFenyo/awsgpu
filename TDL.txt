
TDL :

il faut créer un vocabulaire du corpus, pour la recherche par mots-clés
Il faut créer des liens dans le vocabulaire : par ex Jenkins <=> Forge
et quand on recherche avec mots clés issus de la question, il faut rechercher aussi les chunks avec les mots clés associés à ces liens
Il faut donc un vocabulaire de corpus avec des liens et un glossaire pour éviter la redondance, il faut une normalisation via transformation en minuscules et lemmatisation légère, pour éviter les redondances.

ex : Réponds en une phrase et sans raisonnement. Donne-moi les mots clés de la question suivante, du plus discriminant au moins discriminant, pour une recherche RAG par mots clés : "Quels sont les composants de la forge MES DMP ?"

bon résultat relativement aux expériences précédentes :
Dans un contexte de systèmes informatiques, donne moi une réponse typique de 20 mots maximum correspondant à la question suivante, pour que je puisse identifier, à l'aide d'embeddings, des chunks correspondant à la question, pour implémenter un RAG. Voici la question : 'Quels sont les composants de la forge ?'"


------------------------------------------------------------

processer la recherche par headings, puis la merger

compresser un document

modifier les requêtes et merger les résultats des recherches avec les différentes versions des requêtes

découper une requête en plusieurs sous requêtes s'il y a des relations X->Y et Y->Z, en repérant ces relations par un prompt et un modèle adaptés

faire de la recherche BM25 et fuzzy

reranker

corriger les fautes d'orthographe automatiquement

modifier la requête pour qu'elle affiche précisément l'intention de l'utilisateur

OCR

modifier les références de texte quand les objets référencés ont changé de forme dans le Markdown

identifier les references et les mettre dans les metadata, le reranking permettra de les utiliser si elles sont utiles

markitdown : https://dev.to/leapcell/deep-dive-into-microsoft-markitdown-4if5
word : mammoth => html => BeautifulSoup => Markdown
Excel : pandas => html => BeautifulSoup => Markdown
PPT : pptx => html => BeautifulSoup => Markdown

------------------------------------------------------------

processer la recherche par headings, puis la merger :

(awsgpu-py3.13) fenyo@ordinatlexandre awsgpu % ./scripts/request.sh -n "RGPD" > /tmp/res

collecting chunks for text content: /tmp/chunks-CydZ9WTBdg.jsonl
collecting chunks for headings: /tmp/chunks-CydZ9WTBdg.headings.jsonl
updating chunks (adding titles): /tmp/chunks-CydZ9WTBdg.jsonl.embeddings.ndjson



(awsgpu-py3.13) fenyo@ordinatlexandre awsgpu % cat /tmp/chunks-CydZ9WTBdg.jsonl | jq -r '.chunk_id' | sort -u > /tmp/res1
(awsgpu-py3.13) fenyo@ordinatlexandre awsgpu % cat /tmp/chunks-CydZ9WTBdg.headings.jsonl | jq -r '.chunk_id' | sed 's/md-headings-//' | sed 's/docx\./docx-/' | sort -u > /tmp/res2

pb : presque rien en commun !
chercher sur les titres ne sert pratiquement à rien, car le contenu des titres a peu d'infos, seuls un ou deux titres vont matcher, et on les retrouve déjà dans les chunks (les contenu du chunk, indépendamment des modifs qu'on fait par la suite, reprend le titre, si le rédacteur a correctement rédigé cela). Ce qui est intéressant, c'est de les avoir mis en début de chunk. Les titres servent en fait au bon découpage en chunks !

------------------------------------------------------------

